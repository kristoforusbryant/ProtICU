{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "from utils.losses import protop_loss\n",
    "from utils.sample_parameters import SingleGenerator, HiddenAndKernelGenerator, MonotonicGenerator\n",
    "from utils.sample_parameters import ParamGenerators\n",
    "from models.ProtICU import ProtICU\n",
    "from utils.train_n_test import TrainTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = torch.load('data/in-hospital-mortality/tensors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating class weights\n",
    "perc_mort = np.concatenate((train[1], val[1], test[1])).mean()\n",
    "class_weights = torch.Tensor([perc_mort, 1-perc_mort])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generators_dict = {\n",
    "    # HYPERMARAMETER RANGES\n",
    "    'BATCH_SIZE': SingleGenerator([128, 256, 512]),\n",
    "    'EPOCHS': SingleGenerator([20, 40, 50]),\n",
    "    'OPTIMIZER': SingleGenerator([torch.optim.Adam]),\n",
    "    'LEARNING_RATE': SingleGenerator([1e-5, 5e-5, 1e-4, 5e-4]),\n",
    "    'LOSS': SingleGenerator([protop_loss(class_weights, .5 , .5), protop_loss(class_weights, 1, 1),\n",
    "                             protop_loss(class_weights, .1 , .1), protop_loss(class_weights, 1 , .5),\n",
    "                             protop_loss(class_weights, .5 , .1), protop_loss(class_weights, .3 , .1)]),\n",
    "    'EARLY_STOPPING': SingleGenerator([True]),\n",
    "    'PATIENCE': SingleGenerator(list(range(2,4))),\n",
    "    'MIN_DELTA': SingleGenerator([5e-5, 1e-4, 5e-4, 1e-3, 5e-3]), \n",
    "\n",
    "    # NETWORK PARAMETER RANGES\n",
    "    'HIDDEN_AND_KERNEL_SIZES': HiddenAndKernelGenerator(range(1,4), [64, 128, 256, 512], [3, 5, 7, 9], \n",
    "                               ascending=(True, False)),\n",
    "    'MAXPOOL': SingleGenerator([2]),\n",
    "    'OBO_SIZES': MonotonicGenerator(range(1,3), [64, 128, 256, 512], ascending=False),\n",
    "    'PROTOTYPE_NUM': SingleGenerator([10,20]),\n",
    "    'DROPOUT': SingleGenerator(np.arange(8)/10)\n",
    "} # each of these params are sampled INDEPENDENTLY of one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "gen = ParamGenerators(generators_dict)\n",
    "param_samples = gen.sample(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BATCH_SIZE': 128, 'EPOCHS': 40, 'OPTIMIZER': <class 'torch.optim.adam.Adam'>, 'LEARNING_RATE': 5e-05, 'LOSS': protop_loss_0.5_0.5, 'EARLY_STOPPING': True, 'PATIENCE': 2, 'MIN_DELTA': 0.0001, 'MAXPOOL': 2, 'OBO_SIZES': array([256, 256]), 'PROTOTYPE_NUM': 20, 'DROPOUT': 0.5, 'HIDDEN_SIZES': array([ 64, 128]), 'KERNEL_SIZES': array([7, 3])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:16<00:00,  6.79it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 20.23it/s]\n",
      "  1%|          | 1/115 [00:00<00:14,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.29564544558525085, valid_loss: -0.20622141659259796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:20<00:00,  5.58it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 15.82it/s]\n",
      "  0%|          | 0/115 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train_loss: -0.5244238376617432, valid_loss: -0.6580662131309509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:24<00:00,  4.61it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 15.89it/s]\n",
      "  1%|          | 1/115 [00:00<00:18,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, train_loss: -0.7162585854530334, valid_loss: -0.697081446647644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:16<00:00,  6.96it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 18.55it/s]\n",
      "  1%|          | 1/115 [00:00<00:14,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, train_loss: -0.756279706954956, valid_loss: -0.7457778453826904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:16<00:00,  6.87it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 18.26it/s]\n",
      "  1%|          | 1/115 [00:00<00:17,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, train_loss: -0.7732405066490173, valid_loss: -0.7476105690002441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:15<00:00,  7.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 20.73it/s]\n",
      "  1%|          | 1/115 [00:00<00:14,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, train_loss: -0.7823200821876526, valid_loss: -0.7563960552215576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:14<00:00,  7.82it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 20.45it/s]\n",
      "  1%|          | 1/115 [00:00<00:13,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, train_loss: -0.7867077589035034, valid_loss: -0.767099142074585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:15<00:00,  7.62it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 19.56it/s]\n",
      "  1%|          | 1/115 [00:00<00:13,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss increased, patience count:  1\n",
      "Epoch: 7, train_loss: -0.7923399806022644, valid_loss: -0.7627156972885132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:16<00:00,  6.78it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 17.81it/s]\n",
      "  1%|          | 1/115 [00:00<00:14,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, train_loss: -0.797744631767273, valid_loss: -0.7722408771514893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:17<00:00,  6.67it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 17.87it/s]\n",
      "  1%|          | 1/115 [00:00<00:19,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, train_loss: -0.7994142174720764, valid_loss: -0.7746787071228027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:15<00:00,  7.43it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 20.65it/s]\n",
      "  1%|          | 1/115 [00:00<00:16,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, train_loss: -0.8060867786407471, valid_loss: -0.7773119211196899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:16<00:00,  7.09it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 21.65it/s]\n",
      "  1%|          | 1/115 [00:00<00:12,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, train_loss: -0.8092324137687683, valid_loss: -0.7888762950897217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:14<00:00,  7.99it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 21.79it/s]\n",
      "  1%|          | 1/115 [00:00<00:13,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss increased, patience count:  1\n",
      "Epoch: 12, train_loss: -0.809702455997467, valid_loss: -0.7843737006187439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:14<00:00,  8.08it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 20.90it/s]\n",
      "  1%|          | 1/115 [00:00<00:13,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss increased, patience count:  2\n",
      "Epoch: 13, train_loss: -0.8138859868049622, valid_loss: -0.7818833589553833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [00:14<00:00,  8.07it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 18.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopped at Epoch:  14\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "for i in np.arange(N):\n",
    "    print(param_samples[i])\n",
    "    run = TrainTest(ProtICU, (train, val, test), param_samples[i])\n",
    "    run.train()\n",
    "    stats.append(run.test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'epoch_stopped': 14,\n",
       "  'auroc': 0.7195216900196326,\n",
       "  'auprc': 0.3724263590994855,\n",
       "  'acc': 0.8538315988647115,\n",
       "  'f1': 0.0}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(N):\n",
    "    for key,val in stats[i].items():\n",
    "        param_samples[i][key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(param_samples, 'results/Proto_experiment_nopush_N'+str(N)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProtICU(test[0].shape, 2, [64, 128], [5,3], 2, [256, 128], [0,0,0,0,0,1,1,1,1,1], .2)\n",
    "out, min_dis = model(test[0][:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
